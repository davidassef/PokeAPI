#!/usr/bin/env python3
"""
Relat√≥rio executivo do status de persist√™ncia de imagens.

Este script gera um relat√≥rio completo sobre o estado atual do cache de imagens,
identificando lacunas e fornecendo recomenda√ß√µes para garantir que a aplica√ß√£o
funcione independentemente da API externa.
"""

import os
import sys
import json
import time
from datetime import datetime, timedelta
from pathlib import Path

# Adicionar o diret√≥rio atual ao path para importa√ß√µes
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from app.core.database import SessionLocal
from app.services.image_cache_service import ImageCacheService, PokemonImageCache


class CacheStatusReport:
    def __init__(self):
        self.service = ImageCacheService()
        self.critical_pokemon_range = range(1, 152)  # Gen 1 completa
        
    def generate_comprehensive_report(self):
        """Gera relat√≥rio completo do status do cache."""
        db = SessionLocal()
        try:
            report = {
                'timestamp': datetime.now().isoformat(),
                'summary': {},
                'critical_analysis': {},
                'gaps': {},
                'recommendations': [],
                'technical_details': {}
            }
            
            # An√°lise geral do cache
            total_entries = db.query(PokemonImageCache).count()
            downloaded = db.query(PokemonImageCache).filter(
                PokemonImageCache.is_downloaded == True
            ).count()
            failed = db.query(PokemonImageCache).filter(
                PokemonImageCache.is_downloaded == False,
                PokemonImageCache.download_attempts >= 1
            ).count()
            pending = db.query(PokemonImageCache).filter(
                PokemonImageCache.is_downloaded == False,
                PokemonImageCache.download_attempts == 0
            ).count()
            
            report['summary'] = {
                'total_entries': total_entries,
                'downloaded': downloaded,
                'failed': failed,
                'pending': pending,
                'success_rate': round((downloaded / total_entries * 100) if total_entries > 0 else 0, 1)
            }
            
            # An√°lise dos Pok√©mons cr√≠ticos (Gen 1)
            critical_analysis = self._analyze_critical_pokemon(db)
            report['critical_analysis'] = critical_analysis
            
            # Identificar lacunas
            gaps = self._identify_gaps(db)
            report['gaps'] = gaps
            
            # Gerar recomenda√ß√µes
            recommendations = self._generate_recommendations(report)
            report['recommendations'] = recommendations
            
            # Detalhes t√©cnicos
            technical_details = self._get_technical_details(db)
            report['technical_details'] = technical_details
            
            return report
            
        finally:
            db.close()
    
    def _analyze_critical_pokemon(self, db):
        """Analisa a cobertura dos Pok√©mons cr√≠ticos (Gen 1)."""
        critical_downloaded = 0
        critical_failed = 0
        critical_missing = 0
        
        missing_pokemon = []
        failed_pokemon = []
        
        for pokemon_id in self.critical_pokemon_range:
            entry = db.query(PokemonImageCache).filter(
                PokemonImageCache.pokemon_id == pokemon_id,
                PokemonImageCache.image_type == 'official-artwork'
            ).first()
            
            if not entry:
                critical_missing += 1
                missing_pokemon.append(pokemon_id)
            elif entry.is_downloaded:
                critical_downloaded += 1
            else:
                critical_failed += 1
                failed_pokemon.append({
                    'id': pokemon_id,
                    'attempts': entry.download_attempts,
                    'last_attempt': entry.last_attempt.isoformat() if entry.last_attempt else None
                })
        
        return {
            'total': len(self.critical_pokemon_range),
            'downloaded': critical_downloaded,
            'failed': critical_failed,
            'missing': critical_missing,
            'coverage_rate': round((critical_downloaded / len(self.critical_pokemon_range) * 100), 1),
            'missing_pokemon': missing_pokemon,
            'failed_pokemon': failed_pokemon
        }
    
    def _identify_gaps(self, db):
        """Identifica lacunas no cache."""
        # Lacunas por tipo de imagem
        gaps_by_type = {}
        for image_type in ['official-artwork', 'sprite', 'sprite-shiny', 'home', 'home-shiny']:
            missing = db.query(PokemonImageCache).filter(
                PokemonImageCache.image_type == image_type,
                PokemonImageCache.is_downloaded == False
            ).count()
            gaps_by_type[image_type] = missing
        
        # Lacunas por faixa de ID
        gaps_by_range = {}
        ranges = [(1, 151), (152, 251), (252, 386), (387, 493), (494, 649)]
        for start, end in ranges:
            missing = db.query(PokemonImageCache).filter(
                PokemonImageCache.pokemon_id.between(start, end),
                PokemonImageCache.image_type == 'official-artwork',
                PokemonImageCache.is_downloaded == False
            ).count()
            gaps_by_range[f"{start}-{end}"] = missing
        
        return {
            'by_type': gaps_by_type,
            'by_range': gaps_by_range
        }
    
    def _generate_recommendations(self, report):
        """Gera recomenda√ß√µes baseadas na an√°lise."""
        recommendations = []
        
        # An√°lise de cobertura cr√≠tica
        critical_coverage = report['critical_analysis']['coverage_rate']
        
        if critical_coverage < 80:
            recommendations.append({
                'priority': 'HIGH',
                'type': 'CRITICAL_COVERAGE',
                'description': f'Cobertura cr√≠tica baixa ({critical_coverage}%). Pr√©-carregar imagens Gen 1.',
                'action': 'Execute preload_critical_images.py com retry programado'
            })
        
        if report['summary']['failed'] > 50:
            recommendations.append({
                'priority': 'HIGH',
                'type': 'FAILED_DOWNLOADS',
                'description': f'Muitos downloads falharam ({report["summary"]["failed"]}). Implementar retry inteligente.',
                'action': 'Configure retry autom√°tico com backoff exponencial'
            })
        
        recommendations.append({
            'priority': 'MEDIUM',
            'type': 'FALLBACK_STRATEGY',
            'description': 'Implementar estrat√©gia de fallback para quando API externa falhar',
            'action': 'Garantir que imagens locais sejam servidas mesmo sem internet'
        })
        
        recommendations.append({
            'priority': 'LOW',
            'type': 'MONITORING',
            'description': 'Implementar monitoramento cont√≠nuo do cache',
            'action': 'Crie jobs agendados para verificar e preencher lacunas'
        })
        
        return recommendations
    
    def _get_technical_details(self, db):
        """Obt√©m detalhes t√©cnicos do cache."""
        # Tamanho total do cache
        total_size = 0
        entries = db.query(PokemonImageCache).filter(PokemonImageCache.is_downloaded == True).all()
        
        for entry in entries:
            if os.path.exists(entry.local_path):
                total_size += entry.file_size
        
        # Estat√≠sticas de tentativas
        avg_attempts = db.query(PokemonImageCache).filter(
            PokemonImageCache.download_attempts > 0
        ).count()
        
        return {
            'total_cache_size_mb': round(total_size / (1024 * 1024), 2),
            'cache_directory': str(self.service.cache_dir),
            'supported_image_types': list(self.service.image_urls.keys()),
            'max_download_attempts': self.service.max_download_attempts,
            'retry_delay_hours': self.service.retry_delay_hours
        }
    
    def save_report(self, report, filename='cache_status_report.json'):
        """Salva o relat√≥rio em arquivo JSON."""
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        return filename
    
    def print_executive_summary(self, report):
        """Imprime resumo executivo do relat√≥rio."""
        print("=" * 60)
        print("üìä RELAT√ìRIO EXECUTIVO - STATUS DE PERSIST√äNCIA")
        print("=" * 60)
        
        summary = report['summary']
        critical = report['critical_analysis']
        
        print(f"üìà Status Geral:")
        print(f"   ‚Ä¢ Total de imagens no cache: {summary['total_entries']}")
        print(f"   ‚Ä¢ Downloads bem-sucedidos: {summary['downloaded']} ({summary['success_rate']}%)")
        print(f"   ‚Ä¢ Downloads falhados: {summary['failed']}")
        print(f"   ‚Ä¢ Downloads pendentes: {summary['pending']}")
        
        print(f"\nüéØ An√°lise Pok√©mons Cr√≠ticos (Gen 1):")
        print(f"   ‚Ä¢ Cobertura: {critical['coverage_rate']}% ({critical['downloaded']}/{critical['total']})")
        print(f"   ‚Ä¢ Falhados: {critical['failed']}")
        print(f"   ‚Ä¢ Ausentes: {critical['missing']}")
        
        if critical['coverage_rate'] >= 80:
            print("   ‚úÖ STATUS: BOM - Aplica√ß√£o pode funcionar sem API externa")
        elif critical['coverage_rate'] >= 50:
            print("   ‚ö†Ô∏è  STATUS: MODERADO - Algumas imagens podem n√£o carregar")
        else:
            print("   ‚ùå STATUS: CR√çTICO - Forte depend√™ncia da API externa")
        
        print(f"\nüìã Recomenda√ß√µes Priorit√°rias:")
        for rec in report['recommendations']:
            if rec['priority'] in ['HIGH', 'MEDIUM']:
                print(f"   ‚Ä¢ [{rec['priority']}] {rec['description']}")
        
        print("=" * 60)


def main():
    """Fun√ß√£o principal."""
    print("üìä Gerando relat√≥rio executivo do cache...")
    
    reporter = CacheStatusReport()
    
    try:
        report = reporter.generate_comprehensive_report()
        
        # Imprime resumo executivo
        reporter.print_executive_summary(report)
        
        # Salva relat√≥rio completo
        filename = reporter.save_report(report)
        print(f"üìÑ Relat√≥rio completo salvo em: {filename}")
        
        # Salva tamb√©m vers√£o executiva
        executive_summary = {
            'timestamp': report['timestamp'],
            'critical_coverage': report['critical_analysis']['coverage_rate'],
            'total_downloaded': report['summary']['downloaded'],
            'status': 'GOOD' if report['critical_analysis']['coverage_rate'] >= 80 else 
                     'MODERATE' if report['critical_analysis']['coverage_rate'] >= 50 else 'CRITICAL',
            'next_actions': [rec['action'] for rec in report['recommendations'] if rec['priority'] == 'HIGH']
        }
        
        with open('executive_summary.json', 'w') as f:
            json.dump(executive_summary, f, indent=2)
        
    except Exception as e:
        print(f"‚ùå Erro ao gerar relat√≥rio: {e}")


if __name__ == "__main__":
    main()